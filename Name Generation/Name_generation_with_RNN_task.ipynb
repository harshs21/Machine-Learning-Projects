{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Name generation with RNN-task.ipynb ",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yF1rtUzGUbm",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT-MqO1DG_n3",
        "colab_type": "text"
      },
      "source": [
        "tqdm_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcC0E9RyHAsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import tqdm\n",
        "tqdm.monitor_interval = 0  # workaround for https://github.com/tqdm/tqdm/issues/481\n",
        "\n",
        "\n",
        "class SimpleTqdm():\n",
        "    def __init__(self, iterable=None, total=None, **kwargs):\n",
        "        self.iterable = list(iterable) if iterable is not None else None\n",
        "        self.total = len(self.iterable) if self.iterable is not None else total\n",
        "        assert self.iterable is not None or self.total is not None\n",
        "        self.current_step = 0\n",
        "        self.print_frequency = max(self.total // 50, 1)\n",
        "        self.desc = \"\"\n",
        "\n",
        "    def set_description_str(self, desc):\n",
        "        self.desc = desc\n",
        "\n",
        "    def set_description(self, desc):\n",
        "        self.desc = desc\n",
        "\n",
        "    def update(self, steps):\n",
        "        last_print_step = (self.current_step // self.print_frequency) * self.print_frequency\n",
        "        i = 1\n",
        "        while last_print_step + i * self.print_frequency <= self.current_step + steps:\n",
        "            print(\"*\", end='')\n",
        "            i += 1\n",
        "        self.current_step += steps\n",
        "\n",
        "    def close(self):\n",
        "        print(\"\\n\" + self.desc)\n",
        "\n",
        "    def __iter__(self):\n",
        "        assert self.iterable is not None\n",
        "        self.index = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.index < self.total:\n",
        "            element = self.iterable[self.index]\n",
        "            self.update(1)\n",
        "            self.index += 1\n",
        "            return element\n",
        "        else:\n",
        "            self.close()\n",
        "            raise StopIteration\n",
        "\n",
        "\n",
        "def tqdm_notebook_failsafe(*args, **kwargs):\n",
        "    try:\n",
        "        return tqdm.notebook.tqdm(*args, **kwargs)   \n",
        "    except:\n",
        "        # tqdm is broken on Google Colab\n",
        "        return SimpleTqdm(*args, **kwargs)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLvJ0lc_HDje",
        "colab_type": "text"
      },
      "source": [
        "*keras_utils*.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN3lvCpvHGwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from keras.models import save_model\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from tensorflow.compat.v1.keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "class TqdmProgressCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.epochs = self.params['epochs']\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print('\\nEpoch %d/%d' % (epoch + 1, self.epochs))\n",
        "        if \"steps\" in self.params:\n",
        "            self.use_steps = True\n",
        "            self.target = self.params['steps']\n",
        "        else:\n",
        "            self.use_steps = False\n",
        "            self.target = self.params['samples']\n",
        "        self.prog_bar = tqdm_notebook_failsafe(total=self.target)\n",
        "        self.log_values_by_metric = defaultdict(list)\n",
        "\n",
        "    def _set_prog_bar_desc(self, logs):\n",
        "        for k in self.params['metrics']:\n",
        "            if k in logs:\n",
        "                self.log_values_by_metric[k].append(logs[k])\n",
        "        desc = \"; \".join(\"{0}: {1:.4f}\".format(k, np.mean(values)) for k, values in self.log_values_by_metric.items())\n",
        "        if hasattr(self.prog_bar, \"set_description_str\"):  # for new tqdm versions\n",
        "            self.prog_bar.set_description_str(desc)\n",
        "        else:\n",
        "            self.prog_bar.set_description(desc)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        logs = logs or {}\n",
        "        if self.use_steps:\n",
        "            self.prog_bar.update(1)\n",
        "        else:\n",
        "            batch_size = logs.get('size', 0)\n",
        "            self.prog_bar.update(batch_size)\n",
        "        self._set_prog_bar_desc(logs)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self._set_prog_bar_desc(logs)\n",
        "        self.prog_bar.update(1)  # workaround to show description\n",
        "        self.prog_bar.close()\n",
        "\n",
        "\n",
        "class ModelSaveCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, file_name):\n",
        "        super(ModelSaveCallback, self).__init__()\n",
        "        self.file_name = file_name\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        model_filename = self.file_name.format(epoch)\n",
        "        save_model(self.model, model_filename)\n",
        "        print(\"Model saved in {}\".format(model_filename))\n",
        "\n",
        "\n",
        "# !!! remember to clear session/graph if you rebuild your graph to avoid out-of-memory errors !!!\n",
        "def reset_tf_session():\n",
        "    curr_session = tf.get_default_session()\n",
        "    # close current session\n",
        "    if curr_session is not None:\n",
        "        curr_session.close()\n",
        "    # reset graph\n",
        "    K.clear_session()\n",
        "    # create new session\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    s = tf.InteractiveSession(config=config)\n",
        "    K.set_session(s)\n",
        "    return s"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "i4DHfz7PGUbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bea88584-0b0c-4c39-d44a-2ef64f30f48a"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Hc1tL9GUbv",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "riQydjMZGUbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "bWNnk4aHGUb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "2cd2747a-3731-4365-9bfb-b2e3c86e0d9b"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "ODivL1U-GUb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "ebd759e1-0eb9-45d6-fb95-41c850ab725c"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaZ1yyGHGUcI",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "WfOaqgiOGUcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "81e9a027-1478-4316-bfd3-84b7c0f118b4"
      },
      "source": [
        "tokens = set(''.join(names)) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens.add(pad_token)\n",
        "print(tokens)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'N', 'X', 'o', 'S', '#', 'B', 'E', 'F', 'M', 'k', 'l', 'O', 'T', 'G', 'I', 'a', 'L', 'e', 'd', 'm', 'h', 'j', 'p', 'i', 's', 't', 'u', ' ', 'U', 'r', 'Z', 'n', 'H', 'w', 'v', \"'\", 'Y', 'D', 'f', 'z', 'C', 'g', 'Q', 'V', 'P', 'y', 'A', 'q', 'c', 'R', 'K', 'W', 'J', 'x', '-', 'b'}\n",
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3P9wtDDGUcN",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "ybZCExmKGUcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b80caa27-9f34-4f80-d306-91cc7d38e18a"
      },
      "source": [
        "token_to_id = {s : i for i, s in enumerate(tokens)} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "print(token_to_id)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'N': 0, 'X': 1, 'o': 2, 'S': 3, '#': 4, 'B': 5, 'E': 6, 'F': 7, 'M': 8, 'k': 9, 'l': 10, 'O': 11, 'T': 12, 'G': 13, 'I': 14, 'a': 15, 'L': 16, 'e': 17, 'd': 18, 'm': 19, 'h': 20, 'j': 21, 'p': 22, 'i': 23, 's': 24, 't': 25, 'u': 26, ' ': 27, 'U': 28, 'r': 29, 'Z': 30, 'n': 31, 'H': 32, 'w': 33, 'v': 34, \"'\": 35, 'Y': 36, 'D': 37, 'f': 38, 'z': 39, 'C': 40, 'g': 41, 'Q': 42, 'V': 43, 'P': 44, 'y': 45, 'A': 46, 'q': 47, 'c': 48, 'R': 49, 'K': 50, 'W': 51, 'J': 52, 'x': 53, '-': 54, 'b': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "weoN-yKxGUcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "PbaLGoexGUcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "35ed245d-dc65-455e-95a1-1581a0b629c7"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[27 46 55 15 41 15 17 10  4]\n",
            " [27 13 10  2 29 45  4  4  4]\n",
            " [27 44 29 23 24 24 23 17  4]\n",
            " [27 13 23  2 34 15 31 31 17]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH--kZ1qGUcg",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"./rnn.png\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "pTYH1jpwGUch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = tf.compat.v1.Session()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "gMa2YlCLGUco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOV5Tb1dGUcr",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"./char-nn.png\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "fgafQOhQGUcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t]) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9JMO0cDGUcw",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "c8gQlrYrGUcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ce122064-68cb-4160-d4e5-443af0123350"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oanI2BBHGUc2",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "xNQAHeqEGUc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S14QlUCVGUc6",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "rfQxsrqgGUc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = -tf.reduce_mean(answers_matrix * tf.log(predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkOCPg3lGUdA",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "p955KO-XGUdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7f467b96-61a5-4247-8f2b-daee19863298"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK7J3MioGUdE",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "2xyAhtrFGUdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "ehoxtfAYGUdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "L0oW02eEGUdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "95066562-75c9-49ff-ff6f-e2da25236a4b"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " SGedas\n",
            " Fyse\n",
            " Aranne\n",
            " Hone\n",
            " SRarie\n",
            " Khapine\n",
            " Ledifta\n",
            " Resnarea\n",
            " Hovhito\n",
            " Allter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "oEtRRB1NGUdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b283ecec-270d-4212-c455-2619aee35243"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpakig\n",
            " Trumpi\n",
            " Trumpe\n",
            " Trump\n",
            " Trumpe\n",
            " Trumpo\n",
            " Trumpa\n",
            " Trumpe\n",
            " Trumpana\n",
            " Trumpi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZiFEQPJGUdX",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqLDhU2VGUdg",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "7M2tuoyeGUdh",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfUj7WRGUdl",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63m7xUdbIbFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "UWZIvHGYGUdm",
        "colab_type": "code",
        "colab": {},
        "outputId": "0e1bddb0-ddb0-45c4-afea-f851e6a62395"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "SrJtfkO2GUdv",
        "colab_type": "code",
        "colab": {},
        "outputId": "dba0a104-6333-40c8-8e33-1e0e876bab0c"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVECGI7KGUdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}